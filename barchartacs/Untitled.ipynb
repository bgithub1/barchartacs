{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask import request\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_table\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import plotly_utilities as pu\n",
    "from dashapp import dashapp2 as dashapp\n",
    "import pathlib\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_df_congress = pd.read_html('https://www.pewforum.org/religious-landscape-study/compare/party-affiliation/by/state/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2021\n",
    "month = 11\n",
    "day = 11\n",
    "\n",
    "ice_brent_txt = open(f'{pathlib.Path.home()}/downloads/B_{year}_{month}_{day}.txt').readlines()\n",
    "cols = [\n",
    "    'commod','mmmyy','strike','pc','delta',\n",
    "    'open','high','low','close','settle','price_change',\n",
    "    'volume','oi','oi_change','exer','block_volume','eoo','spread_volume'\n",
    "]\n",
    "csv_lines = [\n",
    "#     ','.join(goodline[0].split(' ')) for goodline in \n",
    "#     goodline[0].replace(' ',',').split(',') for goodline in \n",
    "    goodline[0].split(' ') for goodline in \n",
    "    [\n",
    "        re.findall(\"B [A-Z][a-z]{2}[2-3][0-9] [1-9][0-9]{1,4}\\.[0-9]{2,4} [PC] .+\",line)\n",
    "        for line in ice_brent_txt\n",
    "    ]\n",
    "    if len(goodline)>0\n",
    "]\n",
    "\n",
    "csv_lines = [\n",
    "    line if len(line)==18 else line[0:5] + [line[5],line[5],line[5],line[5],line[5]] + line[6:]\n",
    "    for line in csv_lines\n",
    "]\n",
    "\n",
    "df_brent_crude_ice = pd.DataFrame(\n",
    "    csv_lines,\n",
    "    columns=cols\n",
    ")\n",
    "\n",
    "df_brent_crude_ice = df_brent_crude_ice.fillna(0)\n",
    "poss_float_cols = [\n",
    "    'strike','delta',\n",
    "    'open','high','low','close','settle','price_change',\n",
    "    'volume','oi','oi_change','exer','block_volume','eoo','spread_volume'\n",
    "]\n",
    "float_cols = [c for c in poss_float_cols if c in df_brent_crude_ice.columns.values]\n",
    "for col in float_cols:\n",
    "    df_brent_crude_ice[col] = df_brent_crude_ice[col].str.replace(',','').astype(float) \n",
    "df_brent_crude_ice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_1 = df_brent_crude_ice.mmmyy=='Dec22'\n",
    "c_2 = df_brent_crude_ice.pc == 'C'\n",
    "c_3 = df_brent_crude_ice['strike'] >= 100\n",
    "c_all = c_1 & c_2 & c_3\n",
    "df_brent_crude_ice[c_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# server = Flask(__name__)\n",
    "# app = dash.Dash(\n",
    "#     __name__,\n",
    "#     server = server,\n",
    "#     serve_locally = False,\n",
    "#     requests_pathname_prefix = \"/plotary/dash/\",\n",
    "# )\n",
    "\n",
    "app = dash.Dash(__name__,url_base_pathname=\"/plotary/dash/\")\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Location(id='url', refresh=False),\n",
    "        html.Div([\n",
    "#         html.A([\n",
    "#             html.Div(['goto man-es page'],id=\"logo\")\n",
    "#         ],href='https://man-es.com'),\n",
    "        html.Div([\n",
    "            html.H1('Keine Auswertung ausgew√§hlt. ')\n",
    "        ],id=\"description\"),\n",
    "        # This Link does not seem to be causing an invocation of the callback \n",
    "        dcc.Link('Navigate to https://man-es.com', href='https://man-es.com'),\n",
    "        html.Br(),\n",
    "        # These 2 Links DO seem to be causing an invocation of the callback \n",
    "        dcc.Link('Navigate to \"/plotary/dash/\"', href='/plotary/dash/'),\n",
    "        html.Br(),\n",
    "        dcc.Link('Navigate to \"/plotary/\"', href='/plotary/'),\n",
    "            \n",
    "    ],\n",
    "    id=\"navbar\")]\n",
    ")\n",
    "\n",
    "@app.callback(Output('description', 'children'),\n",
    "              [Input('url', 'pathname')])\n",
    "def display_page(pathname):\n",
    "    print(f'entering callback for pathname {pathname}')\n",
    "    return html.Div([\n",
    "        html.H1('Auswertung Nr {}'.format(pathname))\n",
    "    ])\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run_server(port=8882,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State\n",
    "from dash.exceptions import PreventUpdate\n",
    "\n",
    "import dash_table\n",
    "\n",
    "def make_dt(table_id,df,display_headers=True):\n",
    "    dt = dash_table.DataTable(\n",
    "        id=table_id,\n",
    "        columns=[{\"name\": i, \"id\": i} for i in df.columns],\n",
    "        data=df.to_dict('records'),\n",
    "        filter_action=\"custom\",\n",
    "        sort_action=\"native\",\n",
    "        sort_mode=\"multi\",\n",
    "        column_selectable=\"single\",\n",
    "        row_selectable=\"multi\",\n",
    "#         style_cell={\n",
    "#             'width': '{}%'.format(len(df.columns)),\n",
    "#             'textOverflow': 'ellipsis',\n",
    "#             'overflow': 'hidden'\n",
    "#         }\n",
    "    )\n",
    "    if not display_headers:\n",
    "        dt.style_header = {'display': 'none'}        \n",
    "    return dt\n",
    "\n",
    "    \n",
    "def make_text_centered_div(text):    \n",
    "    col_inner_style = {\n",
    "        'margin':'auto',\n",
    "        'word-break':'break-all',\n",
    "        'word-wrap': 'break-word',\n",
    "        'text-align':'center'\n",
    "    }\n",
    "    return html.Div([text],style=col_inner_style)\n",
    "\n",
    "# make simple DataFrame\n",
    "x = np.arange(0,20)\n",
    "y = x**2\n",
    "df = pd.DataFrame({'x':x,'y':y})\n",
    "\n",
    "# create an \"aggregates\" DataFrame\n",
    "df_agg = pd.DataFrame({'x':[int(df.x.mean())],'y':[df.y.sum()]})\n",
    "\n",
    "# create dash_tables\n",
    "dt = make_dt('mydt',df)\n",
    "dt_agg = make_dt('mydt_agg',df_agg,display_headers=False)\n",
    "agg_title = make_text_centered_div(\"aggregates\")\n",
    "\n",
    "# make app\n",
    "app = dash.Dash(__name__)\n",
    "app.layout = html.Div([dt,agg_title,dt_agg])\n",
    "app.title = \"My DataFrame With Aggs\"\n",
    "\n",
    "@app.callback(\n",
    "    Output('mydt_agg','data'),\n",
    "    [Input('mydt', 'rows'),\n",
    "     Input('mydt', 'selected_row_indices')])\n",
    "def selected_callback(rows,selected_row_indices):\n",
    "    try:\n",
    "        df_selected_rows=pd.DataFrame(rows)\n",
    "        df_new_agg = pd.DataFrame({'x':[df_selected_rows.x.mean()],'y':[df_selected_rows.y.sum()]})\n",
    "        d = df_new_agg.to_dict('records')\n",
    "        return d\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        print(rows,selected_row_indices)\n",
    "        raise PreventUpdate()\n",
    "\n",
    "@app.callback(\n",
    "    Output('mydt','data'),\n",
    "#     [Input('mydt','filter_query')]\n",
    "    [Input('mydt','derived_filter_query_structure')]\n",
    ")\n",
    "def process_filter(filter_query):\n",
    "    print(filter_query,type(filter_query))\n",
    "    return df.to_dict('records')\n",
    "    if filter_query is None or len(filter_query)<=0:\n",
    "        return df.to_dict('records')\n",
    "    df_temp = df.copy()\n",
    "    #{x} > 10 && {y} > 50\n",
    "    fq = str(filter_query).replace('\"','').replace('{',\"\").replace('}',\"\").replace('&&','and')\n",
    "    print(fq)\n",
    "    df_temp = df_temp.query(fq)\n",
    "    return df_temp.to_dict('records')\n",
    "\n",
    "\n",
    "app.run_server(host='127.0.0.1',port=8884)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import pathlib\n",
    "h = pathlib.Path.home()\n",
    "nym = open(f'{h}/downloads/nymex.settle.20200619.s.csv','r').readlines()\n",
    "sio = io.StringIO()\n",
    "sio.writelines(nym)\n",
    "sio.seek(0)\n",
    "df = pd.read_csv(sio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df),len(nym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "z= f'{h}/downloads/nymex.settle.20200619.s.csv.zip'\n",
    "f = zipfile.ZipFile(z).open('nymex.settle.20200619.s.csv')\n",
    "nym2 = [l.decode(\"utf-8\")  for l in f]\n",
    "sio2 = io.StringIO()\n",
    "sio2.writelines(nym2)\n",
    "sio2.seek(0)\n",
    "df2 = pd.read_csv(sio2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "# z= f'{h}/downloads/nymex.settle.20200619.s.csv.zip'\n",
    "z= f'{h}/downloads/df_avg_implied.csv.zip'\n",
    "zo = open(z,'rb').read()\n",
    "zoio = io.BytesIO()\n",
    "zoio.write(zo)\n",
    "# f = zipfile.ZipFile(zoio).open('nymex.settle.20200619.s.csv')\n",
    "f = zipfile.ZipFile(zoio).open('df_avg_implied.csv')\n",
    "nym2 = [l.decode(\"utf-8\")  for l in f]\n",
    "sio2 = io.StringIO()\n",
    "sio2.writelines(nym2)\n",
    "sio2.seek(0)\n",
    "df2 = pd.read_csv(sio2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zoio.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "re.findall(\"\\.zip$\",'df_avg_implied.csv.zip'.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "c = \"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\"\n",
    "content_decoded = base64.b64decode(c)\n",
    "# Use BytesIO to handle the decoded content\n",
    "zoio2 = io.BytesIO(content_decoded)\n",
    "f = zipfile.ZipFile(zoio2).open('df_avg_implied.csv')\n",
    "nym2 = [l.decode(\"utf-8\")  for l in f]\n",
    "sio2 = io.StringIO()\n",
    "sio2.writelines(nym2)\n",
    "sio2.seek(0)\n",
    "df = pd.read_csv(sio2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app = dash.Dash()\n",
    "inp = dcc.Input(id='myinput',)\n",
    "app.layout = html.Div([inp,html.Div(id='c1'),html.Div(id='c2')])\n",
    "\n",
    "@app.callback(\n",
    "    [Output('c1', 'children'),\n",
    "     Output('c2', 'children')],\n",
    "    [Input('myinput', 'value')])\n",
    "def update_graph(v):\n",
    "    return v,v.upper()\n",
    "app.run_server(host='127.0.0.1',port=8844)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dashapp import dashapp2 as dashapp\n",
    "import importlib\n",
    "importlib.reload(dashapp)\n",
    "inp = dcc.Input(id='myinput')\n",
    "dap = dashapp.DashApp()\n",
    "layout = html.Div([inp,html.Div(id='c1'),html.Div(id='c2')])\n",
    "def _dd(input_data):\n",
    "    return [input_data[0][::-1],input_data[0].upper()]\n",
    "d = dashapp.DashLink([(inp,'value')],[('c1','children'),('c2','children')],_dd)\n",
    "dap.add_links([d])\n",
    "dap.create_app(layout,app_port=8844)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "?dashapp.make_dashtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from dashapp import dashapp2 as dashapp\n",
    "import importlib\n",
    "importlib.reload(dashapp)\n",
    "inp = dcc.Input(id='myinput')\n",
    "s = dcc.Store(id='mystore')\n",
    "d1 = dashapp.DashLink(\n",
    "    [(inp,'value')],\n",
    "    [(s,'data')],\n",
    "    lambda i:[pd.DataFrame({'d':[i[0],i[0][::-1]]})])\n",
    "\n",
    "t,tlink = dashapp.make_dashtable('dtable',df_in=pd.DataFrame(),\n",
    "                input_store=s,update_columns=True)\n",
    "\n",
    "\n",
    "dap = dashapp.DashApp()\n",
    "layout = html.Div([inp,html.Div(id='c1'),html.Div(id='c2'),t,s])\n",
    "\n",
    "d2 = dashapp.DashLink([(s,'data')],[('c1','children')],\n",
    "                     lambda i:[i[0]['d']])\n",
    "d3 = dashapp.DashLink([(s,'data')],[('c2','children')],\n",
    "                     lambda i:[i[-1]['d'][::-1]],\n",
    "                     )\n",
    "dap.add_links([d1,d2,d3,tlink])\n",
    "dap.create_app(layout,app_port=8844)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use an dcc.Upload to get new zip file\n",
    "import base64\n",
    "import io\n",
    "import zipfile\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State\n",
    "from dash.exceptions import PreventUpdate\n",
    "\n",
    "import dash_table\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def zipdata_to_df(contents,filename=None):\n",
    "    content_decoded = base64.b64decode(contents)\n",
    "    # Use BytesIO to handle the decoded content\n",
    "    zoio2 = io.BytesIO(content_decoded)\n",
    "    return zipfile_to_df(zoio2,filename)\n",
    "\n",
    "def zipfile_to_df(z,filename=None):\n",
    "    z = zipfile.ZipFile(z)\n",
    "    fn = filename\n",
    "    if fn is None:\n",
    "        fn = z.namelist()[0]\n",
    "    f = z.open(fn.replace('.zip',''))\n",
    "    nym2 = [l.decode(\"utf-8\")  for l in f]\n",
    "    sio2 = io.StringIO()\n",
    "    sio2.writelines(nym2)\n",
    "    sio2.seek(0)\n",
    "    df = pd.read_csv(sio2)\n",
    "    return df\n",
    "\n",
    "def df_to_zipdata(df,filename):\n",
    "    sio2 = io.StringIO()\n",
    "    df.to_csv(sio2,index=False)\n",
    "    sio2.seek(0)\n",
    "    zoio2 = io.BytesIO()\n",
    "    f = zipfile.ZipFile(zoio2,'a',zipfile.ZIP_DEFLATED,False)\n",
    "    f.writestr(filename,sio2.read())\n",
    "    f.close() \n",
    "    zoio2.seek(0)\n",
    "    return zoio2\n",
    "\n",
    "\n",
    "port = 8812\n",
    "url_base_pathname='/app8812/'\n",
    "app = dash.Dash(url_base_pathname=url_base_pathname)\n",
    "main_id='myid'\n",
    "upl = dcc.Upload(\n",
    "    id=f\"{main_id}_uploader\",\n",
    "    children=html.Div(['choose zip file']),\n",
    "    accept = '.zip'\n",
    ")\n",
    "\n",
    "\n",
    "w = html.Div([],id=f\"{main_id}_main_window\")\n",
    "\n",
    "\n",
    "def _make_dt(dt_id,df,displayed_rows=100,page_action='native'):\n",
    "    dt = dash_table.DataTable(\n",
    "        id=dt_id,\n",
    "        page_current= 0,\n",
    "        page_size=displayed_rows,\n",
    "        page_action=page_action,        \n",
    "        \n",
    "    )\n",
    "    dt.data=df.to_dict('rows')\n",
    "    dt.columns=[{\"name\": i, \"id\": i} for i in df.columns.values]                    \n",
    "    return dt\n",
    "\n",
    "savec=None\n",
    "@app.callback(\n",
    "    [Output(w.id,'children')],\n",
    "    [Input(upl.id,'contents')]\n",
    ")\n",
    "def update_window(rawzip):\n",
    "    global savec\n",
    "    if (rawzip is None) or (len(rawzip)<2):\n",
    "        raise PreventUpdate()        \n",
    "    c = rawzip.split(\",\")[1]\n",
    "    savec = c\n",
    "    df = zipdata_to_df(c)\n",
    "    dt = _make_dt(f\"{main_id}_dashtable\",df,displayed_rows=1000)\n",
    "    return [dt]\n",
    "\n",
    "all_rows = [upl,dcc.Loading(children=[w])]\n",
    "app.layout = html.Div(all_rows)\n",
    "app.run_server(port=port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "n = datetime.datetime.now() - datetime.timedelta(1)\n",
    "day_of_week = n.weekday()\n",
    "days_to_subtract = day_of_week - 1\n",
    "if days_to_subtract <0:\n",
    "    days_to_subtract = 7+days_to_subtract\n",
    "past_tuesday = n - datetime.timedelta(days_to_subtract)\n",
    "y = past_tuesday.year\n",
    "m = past_tuesday.month\n",
    "d = past_tuesday.day\n",
    "yyyymmdd = int(str(y))*100*100 + int(str(m))*100 + int(str(d))\n",
    "yyyymmdd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use zip base64 encoded string of a cme settlement file with over 100k rows\n",
    "import base64\n",
    "import io\n",
    "import zipfile\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State\n",
    "from dash.exceptions import PreventUpdate\n",
    "\n",
    "import urllib\n",
    "\n",
    "import dash_table\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "def get_prev_tuesday_yyyymmdd():\n",
    "    n = datetime.datetime.now() - datetime.timedelta(1)\n",
    "    day_of_week = n.weekday()\n",
    "    days_to_subtract = day_of_week - 1\n",
    "    if days_to_subtract <0:\n",
    "        days_to_subtract = 7+days_to_subtract\n",
    "    past_tuesday = n - datetime.timedelta(days_to_subtract)\n",
    "    y = past_tuesday.year\n",
    "    m = past_tuesday.month\n",
    "    d = past_tuesday.day\n",
    "    yyyymmdd = int(str(y))*100*100 + int(str(m))*100 + int(str(d))\n",
    "    return yyyymmdd\n",
    "\n",
    "def zipdata_to_df(contents,filename=None):\n",
    "    content_decoded = base64.b64decode(contents)\n",
    "    # Use BytesIO to handle the decoded content\n",
    "    zoio2 = io.BytesIO(content_decoded)\n",
    "    return zipfile_to_df(zoio2,filename)\n",
    "\n",
    "def zipfile_to_df(z,filename=None):\n",
    "    z = zipfile.ZipFile(z)\n",
    "    fn = filename\n",
    "    if fn is None:\n",
    "        fn = z.namelist()[0]\n",
    "    f = z.open(fn.replace('.zip',''))\n",
    "    nym2 = [l.decode(\"utf-8\")  for l in f]\n",
    "    sio2 = io.StringIO()\n",
    "    sio2.writelines(nym2)\n",
    "    sio2.seek(0)\n",
    "    df = pd.read_csv(sio2)\n",
    "    return df\n",
    "\n",
    "def df_to_zipdata(df,filename):\n",
    "    sio2 = io.StringIO()\n",
    "    df.to_csv(sio2,index=False)\n",
    "    sio2.seek(0)\n",
    "    zoio2 = io.BytesIO()\n",
    "    f = zipfile.ZipFile(zoio2,'a',zipfile.ZIP_DEFLATED,False)\n",
    "    f.writestr(filename,sio2.read())\n",
    "    f.close() \n",
    "    zoio2.seek(0)\n",
    "    return zoio2\n",
    "\n",
    "def get_cme_df(yyyymmdd,multiplier=1):\n",
    "    url=f'ftp://ftp.cmegroup.com/settle/cme.settle.{yyyymmdd}.s.csv.zip'\n",
    "    # get the zip file\n",
    "    mysock = urllib.request.urlopen(url)\n",
    "    memfile = io.BytesIO(mysock.read())\n",
    "    df_main = zipfile_to_df(memfile)\n",
    "    df_main = df_main.append(df_main)\n",
    "    return df_main\n",
    "    \n",
    "\n",
    "def get_cme_zipfile_string(yyyymmdd,multiplier=1):\n",
    "    df_main = get_cme_df(yyyymmdd,multiplier=multiplier)\n",
    "    print(len(df_main))\n",
    "    zd = df_to_zipdata(df_main,'df_main.csv')\n",
    "    zdstring = base64.b64encode(zd.read()).decode(\"utf-8\")\n",
    "    return zdstring\n",
    "    \n",
    "\n",
    "# create a port for the Dash app\n",
    "port = 8812\n",
    "# I'm using a nginx proxy server, so I am routing requests from my public URL\n",
    "#   to a specific route (/app8812/)\n",
    "# For my domain, I would enter https://billybyte.com/app8812/ in my browser address bar\n",
    "url_base_pathname='/app8812/'\n",
    "\n",
    "# create a dash app\n",
    "app = dash.Dash(url_base_pathname=url_base_pathname)\n",
    "\n",
    "# use this prefix as the prefix to all component id's\n",
    "main_id='myid'\n",
    "\n",
    "# get a tuesday, which is probably a day where there was trading on the CME\n",
    "yyyymmdd = get_prev_tuesday_yyyymmdd()\n",
    "# get zip file that has about 100k rows of csv data from the CME Exchanges public FTP site\n",
    "# zdstring will be a compressed version of a csv file, that will be less than one tenth\n",
    "#    the actual size of the csv file.\n",
    "zdstring = get_cme_zipfile_string(yyyymmdd,multiplier=2)\n",
    "# create dcc.Store that holds the string of compressed csv data\n",
    "zipstore = dcc.Store(id=f\"{main_id}_zipstore\",data=zdstring)\n",
    "\n",
    "# create an input box into which the user can enter a query that conforms to the syntax\n",
    "#   of pd.DataFrame.query()\n",
    "inp = dcc.Input(\n",
    "    id=f\"{main_id}_input\",debounce=True,\n",
    "    placeholder=\"Enter Query like: Sym=='ES' & PrevDayVol>250\",\n",
    "    style = dict(width = '50%',display = 'table-cell')\n",
    ")\n",
    "\n",
    "# create a div that will receive the dash_table.DataTable component of the CME data\n",
    "main_window = html.Div([],id=f\"{main_id}_main_window\")\n",
    "\n",
    "# This method get's called in the callback, to create the dash_table.DataTable object\n",
    "def _make_dt(dt_id,df,displayed_rows=100,page_action='native'):\n",
    "    dt = dash_table.DataTable(\n",
    "        id=dt_id,\n",
    "        page_current= 0,\n",
    "        page_size=displayed_rows,\n",
    "        page_action=page_action,        \n",
    "        \n",
    "    )\n",
    "    dt.data=df.to_dict('rows')\n",
    "    dt.columns=[{\"name\": i, \"id\": i} for i in df.columns.values]                    \n",
    "    return dt\n",
    "\n",
    "# This callback get's called when:\n",
    "#   1. When the webpage get's initially loaded, and displays all 100k+ rows of data, or\n",
    "#   2. After you enter a query in the dcc.Input component and hit enter or tab\n",
    "@app.callback(\n",
    "    [Output(main_window.id,'children')],\n",
    "    [Input(inp.id,'value'),Input(zipstore.id,'data')]\n",
    ")\n",
    "def update_window(query,zipfile):\n",
    "    if (zipfile is None) or (len(zipfile)<1):\n",
    "        raise PreventUpdate()        \n",
    "    df = zipdata_to_df(zipfile)\n",
    "    if (query is not None) and (len(query)>0):\n",
    "        df = df.query(query)\n",
    "    dt = _make_dt(f\"{main_id}_dashtable\",df)\n",
    "    return [dt]\n",
    "\n",
    "# create the layout div\n",
    "all_rows = [inp,dcc.Loading(children=[main_window],fullscreen=True),zipstore]\n",
    "app.layout = html.Div(all_rows)\n",
    "# run the app\n",
    "app.run_server(port=port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use CallbackCache\n",
    "from dash.dependencies import Output, Input\n",
    "from flask_caching.backends import FileSystemCache\n",
    "from dash_extensions.callback import CallbackCache, Trigger\n",
    "import dash_table\n",
    "\n",
    "def get_prev_tuesday_yyyymmdd():\n",
    "    n = datetime.datetime.now() - datetime.timedelta(1)\n",
    "    day_of_week = n.weekday()\n",
    "    days_to_subtract = day_of_week - 1\n",
    "    if days_to_subtract <0:\n",
    "        days_to_subtract = 7+days_to_subtract\n",
    "    past_tuesday = n - datetime.timedelta(days_to_subtract)\n",
    "    y = past_tuesday.year\n",
    "    m = past_tuesday.month\n",
    "    d = past_tuesday.day\n",
    "    yyyymmdd = int(str(y))*100*100 + int(str(m))*100 + int(str(d))\n",
    "    return yyyymmdd\n",
    "\n",
    "def get_cme_df(yyyymmdd):\n",
    "    url=f'ftp://ftp.cmegroup.com/settle/cme.settle.{yyyymmdd}.s.csv.zip'\n",
    "    # get the zip file\n",
    "    mysock = urllib.request.urlopen(url)\n",
    "    memfile = io.BytesIO(mysock.read())\n",
    "    df_main = zipfile_to_df(memfile)\n",
    "    df_main = df_main.append(df_main)\n",
    "    return df_main\n",
    "\n",
    "yyyymmdd = get_prev_tuesday_yyyymmdd()\n",
    "df_cme = get_cme_df(yyyymmdd)\n",
    "\n",
    "def _make_dt(dt_id,df,displayed_rows=100,page_action='native'):\n",
    "    dt = dash_table.DataTable(\n",
    "        id=dt_id,\n",
    "        page_current= 0,\n",
    "        page_size=displayed_rows,\n",
    "        page_action=page_action,        \n",
    "        \n",
    "    )\n",
    "    dt.data=df.to_dict('rows')\n",
    "    dt.columns=[{\"name\": i, \"id\": i} for i in df.columns.values]                    \n",
    "    return dt\n",
    "\n",
    "\n",
    "# Create app.\n",
    "# app = dash.Dash(prevent_initial_callbacks=True)\n",
    "app = dash.Dash()\n",
    "app.layout = html.Div([\n",
    "#     html.Button(\"Query data\", id=\"btn\"), dcc.Dropdown(id=\"dd\"), dcc.Graph(id=\"graph\"),\n",
    "    html.Button(\"Query data\", id=\"btn\"), dcc.Input(id=\"dd\",debounce=True), \n",
    "    dcc.Loading(html.Div(id=\"graph\"),fullscreen=True),\n",
    "    dcc.Store(id=\"store\")\n",
    "])\n",
    "# Create (server side) cache. Works with any flask caching backend.\n",
    "cc = CallbackCache(cache=FileSystemCache(cache_dir=\"cache\"))\n",
    "\n",
    "\n",
    "\n",
    "@cc.cached_callback(Output(\"store\", \"data\"), [Trigger(\"btn\", \"n_clicks\")])  # Trigger is like Input, but excluded from args\n",
    "def query_data():\n",
    "    time.sleep(1)  # sleep to emulate a database call / a long calculation\n",
    "#     return px.data.gapminder()\n",
    "    return df_cme\n",
    "\n",
    "search_col = 'Sym'\n",
    "\n",
    "@cc.callback(Output(\"graph\", \"children\"), [Input(\"store\", \"data\"), Input(\"dd\", \"value\")])\n",
    "def update_graph(df, value):\n",
    "    if (value is not None) and (len(value)>0):\n",
    "        try:\n",
    "            df = df.query(value)\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "#     return px.sunburst(df, path=['continent', 'country'], values='pop', color='lifeExp', hover_data=['iso_alpha'])\n",
    "#     fig =  px.sunburst(df, path=['continent', 'country'], values='pop', color='lifeExp', hover_data=['iso_alpha'])\n",
    "#     g = dcc.Graph(figure=fig)\n",
    "    dt = _make_dt(f\"dtid\",df)\n",
    "    return dt\n",
    "\n",
    "\n",
    "# This call registers the callbacks on the application.\n",
    "cc.register(app)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "?dash_table.DataTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h = pathlib.Path.home()\n",
    "csvname=\"nymex.settle.20200609.s.csv\"\n",
    "fullpath = f\"{h}/downloads/{csvname}\"\n",
    "df = pd.read_csv(fullpath)\n",
    "z = df_to_zipdata(df,csvname)\n",
    "# df2 = zipfile_to_df(z,csvname)\n",
    "df2 = zipfile_to_df(z)\n",
    "df2.head(5)\n",
    "# zoio2.seek(0)\n",
    "# len(zoio2.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lines = open(f\"{h}/downloads/billionaires.txt\").readlines()\n",
    "ss = \"[0-9]{1,3}[ ]([A-Z a-z]+)(\\$[0-9]{1,4}[.][0-9]{1,2}B)\"\n",
    "pairs = [re.findall(ss,l) for l in lines]\n",
    "vlist = [float(s[0][1].replace('B','').replace('$','')) for s in pairs if len(s)>0]\n",
    "sum(vlist),len(vlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash_extensions.enrich import Dash, ServersideOutput, Output, Input, State, Trigger\n",
    "from dash.exceptions import PreventUpdate\n",
    "import dash_table\n",
    "\n",
    "class ColumnSelector(dash_table.DataTable):\n",
    "    def __init__(self,dt_id,options=None,\n",
    "                 options_input_dashtable=None,\n",
    "                 displayed_rows=4,\n",
    "                 value=None,style=None):\n",
    "        \n",
    "        self.options_input_dashtable=options_input_dashtable\n",
    "        opts = options\n",
    "        if opts is None:\n",
    "            opts = []\n",
    "        df = pd.DataFrame({'option':opts})            \n",
    "        data=df.to_dict('rows')\n",
    "        columns=[{\"name\": i, \"id\": i} for i in df.columns.values]                    \n",
    "        selected_rows=list(range(len(df)))\n",
    "        \n",
    "        super(ColumnSelector,self).__init__(\n",
    "            id=dt_id,\n",
    "            editable=True,\n",
    "            page_action='none', \n",
    "            style_table={\n",
    "                'overflowY':'auto',\n",
    "                'height': f'{30*(displayed_rows+1)+2}px'\n",
    "            } ,\n",
    "            fixed_rows={'headers': True},\n",
    "            row_selectable='multi',\n",
    "            data=data,\n",
    "            columns=columns,\n",
    "            selected_rows=selected_rows\n",
    "        )\n",
    "    def register_app(self,theapp):\n",
    "        if self.options_input_dashtable is not None:\n",
    "            @theapp.callback(\n",
    "                [\n",
    "                    Output(self.id,'data'),\n",
    "                    Output(self.id,'columns'),\n",
    "                    Output(self.id,'selected_rows')],\n",
    "                [Input(self.options_input_dashtable.id,'columns')]            \n",
    "            )\n",
    "            def _change_options(columns_dict):\n",
    "                if columns_dict is None or len(columns_dict)<=0:\n",
    "                    raise PreventUpdate(\"callback MultiDropdown._change_options: no DataFrame columns\")\n",
    "                names = [c['name'] for c in columns_dict]\n",
    "                df_return = pd.DataFrame({'option':names})\n",
    "                data = df_return.to_dict('records')\n",
    "                columns = [{'name':c,'id':c} for c in df_return.columns.values]\n",
    "                selected_rows=df_return.index.values\n",
    "                return data,columns,selected_rows\n",
    "            return _change_options\n",
    "        else:\n",
    "            return None\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opts = ['red','orange','yellow','green','blue','indigo','violet']\n",
    "df_original= pd.DataFrame({c:list(range(10)) for c in opts})\n",
    "dt = dash_table.DataTable(id='test_input_df',data=df_original.to_dict('records'),\n",
    "                         columns=[{'name':c,'id':c} for c in df.columns.values])\n",
    "dt2 = dash_table.DataTable(id='test_input_df2',data=df_original.to_dict('records'),\n",
    "                         columns=[{'name':c,'id':c} for c in df.columns.values])\n",
    "\n",
    "mdd = ColumnSelector('mdd_id',options_input_dashtable=dt)\n",
    "but = html.Button(\"Click to change cols\",id='change_cols')\n",
    "\n",
    "def reg_but(theapp,original_columns):\n",
    "    @theapp.callback(\n",
    "        Output(dt2.id,'columns'),\n",
    "        [Input(but.id,'n_clicks')],\n",
    "        [State(mdd.id,'data'),State(mdd.id,'selected_rows')]        \n",
    "    )\n",
    "    def _change_cols(n_clicks,data,selected_rows):\n",
    "        \n",
    "        columns = [{'name':c,'id':c} for c in original_columns]\n",
    "        if len(data)>0:\n",
    "            df_mdd = pd.DataFrame(data).loc[selected_rows].sort_index()\n",
    "            cols_to_show = df_mdd['option'].values\n",
    "            columns = [{'name':c,'id':c} for c in cols_to_show]\n",
    "        return columns\n",
    "    return _change_cols   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app = dash.Dash()\n",
    "padd = 1\n",
    "\n",
    "app.layout = html.Div([mdd,but,dt,dt2],\n",
    "                      style={\n",
    "                          'padding-right': f'{padd}%',\n",
    "                          'padding-left': f'{padd}%',\n",
    "                          'display':'grid',\n",
    "                          'grid-template-columns':'1fr 1fr 4fr 4fr',\n",
    "                          'grid-template-rows':'1fr'\n",
    "                      }\n",
    "                     )\n",
    "\n",
    "reg_but(app,opts)\n",
    "mdd.register_app(app)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(port=8813)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dash\n",
    "import dash_table\n",
    "import dash_html_components as html\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'mycol':range(10)})\n",
    "d = df.to_dict('records')\n",
    "cols = [{'name':c,'id':c} for c in df.columns.values]\n",
    "dt1 = dash_table.DataTable(\n",
    "    id='dt1',\n",
    "    data=d,\n",
    "    columns=cols,\n",
    "    page_current= 0,\n",
    "    page_size=4,\n",
    "    page_action='native'\n",
    ")\n",
    "\n",
    "dt2 = dash_table.DataTable(\n",
    "    id='dt2',\n",
    "    data=d,\n",
    "    columns=cols,\n",
    "    page_current= 0,\n",
    "    page_size=4,\n",
    "    page_action='native' \n",
    ")\n",
    "\n",
    "app = dash.Dash()\n",
    "s = {'display':'grid'}\n",
    "app.layout=html.Div(\n",
    "    [dt1,dt2],\n",
    "    style=s\n",
    ")\n",
    "if __name__ == '__main__':\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip list|grep dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "h = pathlib.Path.home()\n",
    "from dashapp import single_page_from_df as spfd#@UnresolvedImport\n",
    "df = pd.read_csv(f\"{h}/downloads/data_csv.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressive_dropdown as progdd\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "\n",
    "init_values_source = dcc.Store(id='mystore',data=df.to_dict('records'))\n",
    "pdd = progdd.ProgressiveDropdown(init_values_source,'pddd',3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes[(df.dtypes=='object') | (df.dtypes=='float64')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test1(html.Div):\n",
    "    def __init__(self,test_id,myvalue=-1):\n",
    "        self.myvalue = myvalue\n",
    "        super(Test1,self).__init__(['testit'],id=f'test1{test_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = Test1('t1',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(\"https://yidi.imfast.io/c03db104479aa2d6f3c49743cb01d60ab190d8b3/data/Pinnacle_Premier%20League.json\") as url:\n",
    "    data = json.loads(url.read().decode())\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pg_pandas as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pga = pg.PgPandas(\n",
    "    username='root',password='CJu84cs@cI9',databasename='thequantedge',\n",
    "    dburl='127.0.0.1:3306',dbflavor='mysql+pymysql://')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "select * from membership_orders;\n",
    "\"\"\"\n",
    "df_mo = pga.get_sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "select * from users;\n",
    "\"\"\"\n",
    "df_users = pga.get_sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spi_matches = pd.read_csv(\"https://projects.fivethirtyeight.com/soccer-api/club/spi_matches.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "h = pathlib.Path.home()\n",
    "d = f\"{h}/downloads\"\n",
    "df_pop_by_state = pd.read_csv(f\"{d}/population_by_state.csv\")\n",
    "df_electoral_college_by_state = pd.read_csv(f\"{d}/electoral_college_by_state.csv\")\n",
    "df_pop_vote_by_state = pd.read_csv(f\"{d}/popular_vote_2016_by_state.csv\")\n",
    "df_pop_vote_by_state.Votes = df_pop_vote_by_state.Votes.str.replace(',','').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop_vote_by_state[df_pop_vote_by_state['State Code']=='AZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_electoral_college_by_state.columns.values)\n",
    "print(df_pop_by_state.columns.values)\n",
    "print(df_pop_vote_by_state.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_electoral = df_electoral_college_by_state.merge(df_pop_by_state,on='State',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_electoral['percapita_power'] = 1000000* df_electoral.qty/df_electoral['2018 Population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_electoral.sort_values('percapita_power',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop_vote_by_state_pt = pd.pivot_table(\n",
    "    df_pop_vote_by_state,index=['State'],\n",
    "    values='Votes',columns=['Party'], aggfunc=np.sum)\n",
    "df_pop_vote_by_state_pt = df_pop_vote_by_state_pt.fillna(0)#[['DEM','REP']]\n",
    "df_pop_vote_by_state_pt.index.name = None\n",
    "df_pop_vote_by_state_pt['State'] = df_pop_vote_by_state_pt.index\n",
    "df_pop_vote_by_state_pt.index = list(range(len(df_pop_vote_by_state_pt)))\n",
    "df_pop_vote_by_state_pt = df_pop_vote_by_state_pt[['State','DEM','REP']]\n",
    "# df_pop_vote_by_state_pt.DEM = df_pop_vote_by_state_pt.DEM.str.replace(',','').astype(int)\n",
    "# df_pop_vote_by_state_pt.REP = df_pop_vote_by_state_pt.REP.str.replace(',','').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pop_vote_by_state_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_electoral_2 = df_electoral.merge(df_pop_vote_by_state_pt,on='State')\n",
    "df_electoral_2['dem_stranded'] = df_electoral_2.apply(\n",
    "    lambda r: r.DEM if r.DEM < r.REP else 0,axis=1)\n",
    "df_electoral_2['rep_stranded'] = df_electoral_2.apply(\n",
    "    lambda r: r.REP if r.REP < r.DEM else 0,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_electoral_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_electoral_2.dem_stranded.sum(),df_electoral_2.DEM.sum())\n",
    "print(df_electoral_2.rep_stranded.sum(),df_electoral_2.REP.sum())\n",
    "num_dem_wins = len(df_electoral_2[df_electoral_2.rep_stranded>0])\n",
    "num_rep_wins = len(df_electoral_2[df_electoral_2.dem_stranded>0])\n",
    "print(num_dem_wins,num_rep_wins)\n",
    "df_electoral_2['perc_pop_voted'] = (df_electoral_2.DEM + df_electoral_2.REP)/df_electoral_2['2018 Population']\n",
    "df_electoral_2[['State','2018 Population','perc_pop_voted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_electoral_2[df_electoral_2.dem_stranded>0].sort_values('dem_stranded',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_pe_monthly_txt = open(f\"{d}/sp500_pe_monthly.txt\",'r').readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "l = sp_pe_monthly_txt[3].replace('\\n','').replace(',','').replace('\\t',' ').lower()\n",
    "re.split('[a-z]{1,5}[ ][0-9]{1,2}[ ]{1,3}[1-2][0-9]{3}',l)\n",
    "a = [l.replace('\\n','').replace(',','').replace('\\t',' ').lower() for l in sp_pe_monthly_txt[1:]]\n",
    "prices = [re.split('[a-z]{1,5}[ ][0-9]{1,2}[ ]{1,3}[1-2][0-9]{3}',l)[1].strip() for l in a]\n",
    "months = {'jan':1,'feb':2,'mar':3,'apr':4, 'may':5, 'jun':6, 'jul':7, 'aug':8, 'sep':9, 'oct':10, 'nov':11, 'dec':12}\n",
    "dates = [re.split('[0-9]{1,3}[.][0-9]{2}',l)[0].strip().split(' ') for l in a]\n",
    "dates = [int(dd[2])*100*100+months[dd[0]]*100+int(dd[1]) for dd in dates]\n",
    "prices = [float(p) for p in prices]\n",
    "df_pe = pd.DataFrame({'yyyymmdd':dates,'pe':prices})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pe[(df_pe.yyyymmdd>20080101) & (df_pe.yyyymmdd<20100101)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pe[df_pe.yyyymmdd>20080101].plot(x='yyyymmdd',y='pe',kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "response = urllib.request.urlopen('https://storage.googleapis.com/nflnfltest/public/nfl_lineup.json')\n",
    "nfl_impact_text = response.read()\n",
    "nfl_impact_dicts = json.loads(nfl_impact_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_impact_dicts[1]['lineup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[nfl['team_name'] for nfl in nfl_impact_dicts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various examples with Subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic subplots example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/Mining-BTC-180.csv\")\n",
    "\n",
    "for i, row in enumerate(df[\"Date\"]):\n",
    "    p = re.compile(\" 00:00:00\")\n",
    "    datetime = p.split(df[\"Date\"][i])[0]\n",
    "    df.iloc[i, 1] = datetime\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.03,\n",
    "    specs=[[{\"type\": \"table\"}],\n",
    "           [{\"type\": \"scatter\"}],\n",
    "           [{\"type\": \"scatter\"}]]\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df[\"Date\"],\n",
    "        y=df[\"Mining-revenue-USD\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"mining revenue\"\n",
    "    ),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df[\"Date\"],\n",
    "        y=df[\"Hash-rate\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"hash-rate-TH/s\"\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Date\", \"Number<br>Transactions\", \"Output<br>Volume (BTC)\",\n",
    "                    \"Market<br>Price\", \"Hash<br>Rate\", \"Cost per<br>trans-USD\",\n",
    "                    \"Mining<br>Revenue-USD\", \"Trasaction<br>fees-BTC\"],\n",
    "            font=dict(size=10),\n",
    "            align=\"left\"\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[df[k].tolist() for k in df.columns[1:]],\n",
    "            align = \"left\")\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    showlegend=False,\n",
    "    title_text=\"Bitcoin mining stats for 180 days\",\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simpler version of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = pu.plotly_plot(df[['Date','Number-transactions']],x_column='Date')\n",
    "# fig2['data']\n",
    "figm = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.03,\n",
    "    specs=[\n",
    "        [{\"type\": \"table\"}],\n",
    "        [{\"type\": \"scatter\"}],\n",
    "#         [{\"type\": \"scatter\"}]\n",
    "    ]\n",
    ")\n",
    "tab1 =   go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Date\", \"Number<br>Transactions\", \"Output<br>Volume (BTC)\",\n",
    "                    \"Market<br>Price\", \"Hash<br>Rate\", \"Cost per<br>trans-USD\",\n",
    "                    \"Mining<br>Revenue-USD\", \"Trasaction<br>fees-BTC\"],\n",
    "            font=dict(size=10),\n",
    "            align=\"left\"\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[df[k].tolist() for k in df.columns[1:]],\n",
    "            align = \"left\")\n",
    ")\n",
    "\n",
    "figm.add_trace(tab1,row=1,col=1)\n",
    "figm.add_trace(fig2['data'][0],row=2,col=1)\n",
    "figm.update_layout(fig2['layout'])\n",
    "\n",
    "# fig2['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Suplots with dash_bootstrap_components \n",
    "use dcc.Row and dcc.Col to form a simple grid, within a dcc.Tabs component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A simple app demonstrating how to dynamically render tab content containing\n",
    "dcc.Graph components to ensure graphs get sized correctly. We also show how\n",
    "dcc.Store can be used to cache the results of an expensive graph generation\n",
    "process so that switching tabs is fast.\n",
    "\"\"\"\n",
    "import time\n",
    "\n",
    "import dash\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from dash.dependencies import Input, Output\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "app = dash.Dash(external_stylesheets=[dbc.themes.LUX])\n",
    "\n",
    "app.layout = dbc.Container(\n",
    "    [\n",
    "        dcc.Store(id=\"store\"),\n",
    "        html.H1(\"Dynamically rendered tab content\"),\n",
    "        html.Hr(),\n",
    "        dbc.Button(\n",
    "            \"Regenerate graphs\",\n",
    "            color=\"primary\",\n",
    "            block=True,\n",
    "            id=\"button\",\n",
    "            className=\"mb-3\",\n",
    "        ),\n",
    "        dbc.Tabs(\n",
    "            [\n",
    "                dbc.Tab(label=\"Scatter\", tab_id=\"scatter\"),\n",
    "                dbc.Tab(label=\"Histograms\", tab_id=\"histogram\"),\n",
    "            ],\n",
    "            id=\"tabs\",\n",
    "            active_tab=\"scatter\",\n",
    "        ),\n",
    "        html.Div(id=\"tab-content\", className=\"p-4\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"tab-content\", \"children\"),\n",
    "    [Input(\"tabs\", \"active_tab\"), Input(\"store\", \"data\")],\n",
    ")\n",
    "def render_tab_content(active_tab, data):\n",
    "    \"\"\"\n",
    "    This callback takes the 'active_tab' property as input, as well as the\n",
    "    stored graphs, and renders the tab content depending on what the value of\n",
    "    'active_tab' is.\n",
    "    \"\"\"\n",
    "    if active_tab and data is not None:\n",
    "        if active_tab == \"scatter\":\n",
    "            return dcc.Graph(figure=data[\"scatter\"])\n",
    "        elif active_tab == \"histogram\":\n",
    "            return dbc.Row(\n",
    "                [\n",
    "#                     dbc.Col(dcc.Graph(figure=data[\"hist_1\"]), width=6),\n",
    "#                     dbc.Col(dcc.Graph(figure=data[\"hist_2\"]), width=6),\n",
    "                    dbc.Col(dcc.Graph(figure=data['figm'])),\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "    return \"No tab selected\"\n",
    "\n",
    "\n",
    "@app.callback(Output(\"store\", \"data\"), [Input(\"button\", \"n_clicks\")])\n",
    "def generate_graphs(n):\n",
    "    \"\"\"\n",
    "    This callback generates three simple graphs from random data.\n",
    "    \"\"\"\n",
    "    if not n:\n",
    "        # generate empty graphs when app loads\n",
    "        return {k: go.Figure(data=[]) for k in [\"scatter\", \"hist_1\", \"hist_2\"]}\n",
    "\n",
    "    # simulate expensive graph generation process\n",
    "#     time.sleep(2)\n",
    "\n",
    "    # generate 100 multivariate normal samples\n",
    "    data = np.random.multivariate_normal([0, 0], [[1, 0.5], [0.5, 1]], 100)\n",
    "\n",
    "    scatter = go.Figure(\n",
    "        data=[go.Scatter(x=data[:, 0], y=data[:, 1], mode=\"markers\")]\n",
    "    )\n",
    "    figm = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        shared_xaxes=False,\n",
    "        horizontal_spacing=0.03,\n",
    "        specs=[\n",
    "            [{\"type\": \"scatter\"},{\"type\": \"scatter\"}],\n",
    "        ]\n",
    "    )\n",
    "#     figm.add_trace(go.Histogram(x=data[:, 0]),row=1,col=1)\n",
    "#     figm.add_trace(go.Histogram(x=data[:, 1]),row=1,col=2)\n",
    "    figm.add_traces(\n",
    "        [\n",
    "            go.Histogram(x=data[:, 0]),\n",
    "            go.Histogram(x=data[:, 1])\n",
    "        ],\n",
    "        rows = [1,1],\n",
    "        cols = [1,2]\n",
    "    )\n",
    "    \n",
    "#     hist_1 = go.Figure(\n",
    "#         data=[go.Histogram(x=data[:, 0])],\n",
    "#         layout=go.Layout(margin={'t': 0})\n",
    "#     )\n",
    "#     hist_2 = go.Figure(\n",
    "#         data=[go.Histogram(x=data[:, 1])],\n",
    "#         layout=go.Layout(margin={'t': 0})\n",
    "#     )\n",
    "\n",
    "    # save figures in a dictionary for sending to the dcc.Store\n",
    "#     return {\"scatter\": scatter, \"hist_1\": hist_1, \"hist_2\": hist_2, \"figm\":figm}\n",
    "    return {\"scatter\": scatter, \"figm\":figm}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=False, port=8884)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = np.random.multivariate_normal([0, 0], [[1, 0.5], [0.5, 1]], 100)\n",
    "\n",
    "figm = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    shared_xaxes=False,\n",
    "    horizontal_spacing=0.03,\n",
    "    specs=[\n",
    "        [{\"type\": \"scatter\"},{\"type\": \"scatter\"}],\n",
    "    ]\n",
    ")\n",
    "figm.add_traces(\n",
    "    [\n",
    "        go.Histogram(x=data[:, 0]),\n",
    "        go.Histogram(x=data[:, 1])\n",
    "    ],\n",
    "    rows = [1,1],\n",
    "    cols = [1,2]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
