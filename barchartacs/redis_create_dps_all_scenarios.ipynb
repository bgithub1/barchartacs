{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame for all scenarios of the DPS strategy\n",
    "DPS = Downside Put Strategy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a hedge strategy and use data on ^GSPC from yahoo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the cost/revenue of the hedge.\n",
    "The put hedge that you will buy will initially be below the current SP price by a percentage which you set in the variable ```put_perc_otm```.  When the price of the SP rises high enough so that you can raise the strike price of the hedge, you sell the current put (if there is any value in it) and buy a new put that is ```put_perc_otm``` percent higher than the previous put.  In this way, you are not letting your hedge get too far from the money.\n",
    "\n",
    "\n",
    "* Remember that, since you are comparing this put strategy to \"Buy-And-Hold\"\n",
    "  * Rolls to a higher strike are a cost to the strategy\n",
    "  * Rolls to a lower strike are revenue to the strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bperlman1/Virtualenvs3/dashrisk5/lib/python3.6/site-packages/pandas_datareader/compat/__init__.py:7: FutureWarning:\n",
      "\n",
      "pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "if  not './' in sys.path:\n",
    "    sys.path.append('./')\n",
    "if  not '../' in sys.path:\n",
    "    sys.path.append('../')\n",
    "\n",
    "from barchartacs import build_db\n",
    "from barchartacs import db_info\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import datetime\n",
    "# from dateutil.relativedelta import relativedelta\n",
    "import io\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from barchartacs import pg_pandas as pg\n",
    "import mibian\n",
    "import py_vollib\n",
    "import importlib\n",
    "from py_vollib import black\n",
    "from py_vollib.black import implied_volatility\n",
    "import ipdb,pdb\n",
    "import traceback\n",
    "import pandas_datareader.data as pdr\n",
    "from scipy.stats import norm\n",
    "\n",
    "from dashapp import dashapp2 as dashapp\n",
    "\n",
    "import pyarrow as pa\n",
    "import redis\n",
    "import time\n",
    "import schedule_it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open a redis port.  This implies that a redis server is running.\n",
    "##### see the ipynb notebook ```redis_server.ipynb```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "redis_port = 6379\n",
    "redis_db = redis.Redis(host = 'localhost',port=6379,db=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redis_df(key):\n",
    "    context = pa.default_serialization_context()\n",
    "    df = context.deserialize(redis_db.get(key))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_redis_df(key,df):\n",
    "    context = pa.default_serialization_context()\n",
    "    redis_db.set(key, context.serialize(df).to_buffer().to_pybytes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule_updates(hour,update_callback):\n",
    "    logger = schedule_it.init_root_logger(\"logfile.log\", \"INFO\")\n",
    "    while True:\n",
    "        logger.info(f\"scheduling update for hour {hour}\")\n",
    "        sch = schedule_it.ScheduleNext('hour', hour,logger = logger)\n",
    "        sch.wait()\n",
    "        logger.info(f\"updating history\")\n",
    "        update_db()\n",
    "        logger.info(f\"sleeping for an hour before next scheduling\")\n",
    "        time.sleep(60*60)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 01: define important functions that are used below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_to_yyyymmdd(d):\n",
    "    return int(d.year)*100*100 + int(d.month)*100 + int(d.day)\n",
    "\n",
    "def str_to_yyyymmdd(d,sep='-'):\n",
    "    try:\n",
    "        dt = datetime.datetime.strptime(str(d)[:10],f'%Y{sep}%m{sep}%d')\n",
    "    except:\n",
    "        return None\n",
    "    s = '%04d%02d%02d' %(dt.year,dt.month,dt.day)\n",
    "    return int(s)\n",
    "\n",
    "def str_to_date(d,sep='-'):\n",
    "    try:\n",
    "        dt = datetime.datetime.strptime(str(d)[:10],f'%Y{sep}%m{sep}%d')\n",
    "    except:\n",
    "        return None\n",
    "    return dt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_put_spread(\n",
    "    atm_vol,current_hedge_strike,prev_hedge_strike,\n",
    "    hedge_date,prev_hedge_date,rate,put_perc_otm,years_to_hedge):\n",
    "    '''\n",
    "    !! This should only be exexuted on rows of dft where dft.time_to_hedge==True !!\n",
    "\n",
    "    Calculate the value of the option spread where the legs are: \n",
    "      1. the current_hedge_strike \n",
    "      2. previous hedge strike\n",
    "    The value will be positive if you are buying the spread b/c you are rolling\n",
    "      the previous hedge forward (to a higher strike).\n",
    "    The value will be negative if you are selling the spread b/c you are rolling\n",
    "      the previous hedge backward (to a lower strike)\n",
    "    '''\n",
    "     #black.black(flag, F, K, t, r, sigma)\n",
    "    atm_vol = atm_vol\n",
    "    if (np.isnan(prev_hedge_strike)) or (prev_hedge_strike < current_hedge_strike):\n",
    "        curr_strike_vol = atm_vol + .04 \n",
    "        prev_strike_vol = atm_vol + .08\n",
    "    else:\n",
    "        curr_strike_vol = atm_vol - .04 \n",
    "        prev_strike_vol = atm_vol - .06\n",
    "\n",
    "    days_left_in_prev_hedge = (hedge_date - prev_hedge_date).days\n",
    "\n",
    "    # calculate remaining of previous hedge\n",
    "    if np.isnan(prev_hedge_strike):\n",
    "        underlying_price = current_hedge_strike * (1+put_perc_otm)\n",
    "        curr_hedge =  black.black('p', underlying_price, current_hedge_strike, years_to_hedge,rate, curr_strike_vol)\n",
    "        remaining_opt_value = 0\n",
    "    elif prev_hedge_strike < current_hedge_strike:\n",
    "        # we are rolling up b/c the market is put_perc_otm ABOVE the current_hedge\n",
    "        underlying_price = current_hedge_strike * (1+put_perc_otm)\n",
    "        curr_hedge =  black.black('p', underlying_price, current_hedge_strike, years_to_hedge,rate, curr_strike_vol)\n",
    "        if days_left_in_prev_hedge > years_to_hedge*365:\n",
    "            remaining_opt_value = 0\n",
    "        else:\n",
    "            time_remaining = days_left_in_prev_hedge/(years_to_hedge*365)\n",
    "            remaining_opt_value = black.black('p', underlying_price, prev_hedge_strike, \n",
    "                                              time_remaining, rate, prev_strike_vol)\n",
    "    else:\n",
    "        # we are rolling down b/c the market is put_perc_otm BELOW the current_hedge\n",
    "        underlying_price = current_hedge_strike * (1-put_perc_otm)\n",
    "        curr_hedge =  black.black('p', underlying_price, current_hedge_strike, years_to_hedge, rate, curr_strike_vol)\n",
    "        if days_left_in_prev_hedge > years_to_hedge*365:\n",
    "            remaining_opt_value = prev_hedge_strike - underlying_price\n",
    "        else:\n",
    "            remaining_opt_value =  black.black('p', underlying_price, prev_hedge_strike, years_to_hedge, rate, prev_strike_vol)\n",
    "\n",
    "\n",
    "    return curr_hedge - remaining_opt_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yyyymmdd_to_dt_string(yyyymmdd_int):\n",
    "    y = str(yyyymmdd_int)[0:4]\n",
    "    mn = str(yyyymmdd_int)[4:6]\n",
    "    d = str(yyyymmdd_int)[6:8]\n",
    "    return f\"{y}-{mn}-{d}\"\n",
    "\n",
    "def dt_to_yyyymmdd(dt):\n",
    "    yyyymmdd = int(dt.year)*100*100 + int(dt.month)*100 + int(dt.day)\n",
    "    return yyyymmdd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 02: Define methods that creates the dataframe called ```dft``` which has all of the strategy info, incluing hedge values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataInputs():\n",
    "    def __init__(self):\n",
    "        self.df_spy = get_redis_df('df_spy')\n",
    "        self.df_vix = get_redis_df('df_vix')\n",
    "        self.df_1yr_rate = get_redis_df('df_1yr_rate')\n",
    "        self.df_div = get_redis_df('df_div')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_dft(put_perc_otm,years_to_hedge,\n",
    "              yyyymmdd_beg=None,yyyymmdd_end=None,use_fast=True,\n",
    "              data_inputs=None):\n",
    "    if data_inputs is None:\n",
    "        df_spy = get_redis_df('df_spy')\n",
    "        df_vix = get_redis_df('df_vix')\n",
    "        df_1yr_rate = get_redis_df('df_1yr_rate')\n",
    "        df_div = get_redis_df('df_div')\n",
    "    else:\n",
    "        df_spy = data_inputs.df_spy\n",
    "        df_vix = data_inputs.df_vix\n",
    "        df_1yr_rate = data_inputs.df_1yr_rate\n",
    "        df_div = data_inputs.df_div\n",
    "        \n",
    "            \n",
    "    # Create a lambda that converts yyyymmdd integer to a datetime object\n",
    "    yyyymmdd_to_dt = lambda v:datetime.datetime(\n",
    "            int(str(v)[0:4]),int(str(v)[4:6]),int(str(v)[6:8])\n",
    "    )\n",
    "\n",
    "    # Grab only the relevant columns from df_spy\n",
    "    dft = df_spy[['settle_date','close','high','low']]\n",
    "    if yyyymmdd_beg is not None:\n",
    "        dft = dft[dft.settle_date>=yyyymmdd_beg]\n",
    "    if yyyymmdd_end is not None:\n",
    "        dft = dft[dft.settle_date<=yyyymmdd_end]\n",
    "        \n",
    "    # Create a datetime settle date, along with the yyyymmdd settle_date column\n",
    "    dft['settle_dt'] = dft.settle_date.apply(yyyymmdd_to_dt)\n",
    "#     print(f\"create_dft inputs:{put_perc_otm,years_to_hedge,yyyymmdd_beg,yyyymmdd_end}\")\n",
    "    # Initialize currrent_strike, which is below the money\n",
    "    current_long_price = dft.iloc[0].close\n",
    "    current_strike = current_long_price * (1 - put_perc_otm)\n",
    "    current_strike_array = [current_strike]\n",
    "\n",
    "    # Create an array of high and low values, to speed up loop processing    \n",
    "    m = dft[['high','low']].values\n",
    "\n",
    "    # Loop here to determine the hedge strikes\n",
    "    for i in range(1,len(m)):\n",
    "        # Get high and low\n",
    "        curr_high = m[i][0]\n",
    "        curr_low = m[i][1]\n",
    "        # If the price rises past current_strike * (1 + put_perc_otm) * (1+ put_perc_otm)\n",
    "        #   then you want to roll the put strike up,essentially BUYING a put spread\n",
    "        if curr_high  >= current_strike * (1 + put_perc_otm)**2:\n",
    "            # roll strikes up, like buying put spreads as market goes up\n",
    "            current_strike = current_strike * (1 + put_perc_otm)\n",
    "        # If the price falls below current_strike * (1 - put_perc_otm) * (1- put_perc_otm)\n",
    "        #   then you want to roll the put strike down, essentially SELLING a put spread\n",
    "        elif curr_low <= current_strike * (1 - put_perc_otm)**2:\n",
    "            # Roll strikes down (like selling put spreads as market drops)\n",
    "            current_strike = current_strike * (1 - put_perc_otm)\n",
    "        # Accumulate the current_strike (it either remained unchanged, went up, or went down)\n",
    "        current_strike_array.append(current_strike)\n",
    "\n",
    "    # Update dft with the current_strike array    \n",
    "    dft['current_hedge_strike'] = current_strike_array\n",
    "    # Create previous strike, so that you can tell when you have to buy or sell\n",
    "    #   put spreads to roll your hedge to a new higher or lower level.\n",
    "    dft['prev_hedge_strike'] = dft.current_hedge_strike.shift(1)\n",
    "    \n",
    "    # The next 2 lines are where you determine the dates on which you execute hedges\n",
    "    dft.loc[dft.prev_hedge_strike!=dft.current_hedge_strike,'time_to_hedge'] = True\n",
    "    dft.loc[dft.prev_hedge_strike==dft.current_hedge_strike,'time_to_hedge'] = False\n",
    "\n",
    "    # On the next 4 rows, create the hedge_date, which will be used for calculating put prices.\n",
    "    dft.loc[dft.time_to_hedge,'hedge_date'] = dft.loc[dft.time_to_hedge].settle_date\n",
    "    #      Give all rows of dft that are NOT rows where time_to_hedge == True a value of the min settle_date\n",
    "    dft.loc[dft.time_to_hedge==False,'hedge_date'] = dft.settle_date.min()\n",
    "    #      This expanding command will make each row's hedge_date either the last hedge_date, or a new hedge_date\n",
    "    dft.hedge_date = dft.hedge_date.expanding(min_periods=1).max()\n",
    "    #      Now make the hedge_date a datetime object\n",
    "    dft.hedge_date = dft.hedge_date.apply(yyyymmdd_to_dt)\n",
    "    \n",
    "    # Create days_of_hedge, which will give you the total days that the hedge was on\n",
    "    dft['prev_hedge_date'] = dft.hedge_date.shift(1)\n",
    "    dft['days_of_hedge'] = (dft.settle_dt - dft.hedge_date).dt.days        \n",
    "    dft.loc[dft.time_to_hedge,'days_of_hedge'] = (dft[dft.time_to_hedge].hedge_date - dft[dft.time_to_hedge].prev_hedge_date).dt.days\n",
    "\n",
    "    # Obtain atm_vol from the VIX\n",
    "#     df_vix = fetch_history('^VIX',sp_data_beg_date,sp_data_end_date)\n",
    "    df_vix2 = df_vix[['settle_date','close']]\n",
    "    df_vix2 = df_vix2.rename(columns={'close':'atm_vol'})\n",
    "    df_vix2.atm_vol = df_vix2.atm_vol / 100\n",
    "    dft = dft.merge(df_vix2,on='settle_date',how='inner')\n",
    "\n",
    "    # Obtain interest rates fro the 1 year treasury rate\n",
    "    dft = dft.merge(df_1yr_rate,on='settle_date',how='inner')\n",
    "\n",
    "    # Obtain the divident yield from the SP dividend yield dataframe\n",
    "    dft['year'] = dft.settle_date.apply(lambda v:int(str(v)[0:4]))\n",
    "    df_div = pd.read_csv('sp_div_yield.csv')    \n",
    "    dft = dft.merge(df_div,on='year',how='inner')\n",
    "\n",
    "    # Now calculate cost/revenue of buying put spreads, or selling put spreads\n",
    "    def _calc_put_spread(r):\n",
    "        return calc_put_spread(\n",
    "            r.atm_vol,r.current_hedge_strike,r.prev_hedge_strike,\n",
    "            r.hedge_date,r.prev_hedge_date,r.rate,put_perc_otm,years_to_hedge)\n",
    "    dft.loc[dft.time_to_hedge,'hedge'] = dft.loc[dft.time_to_hedge].apply(_calc_put_spread,axis=1)\n",
    "    dft.loc[dft.time_to_hedge==False,'hedge'] = 0\n",
    "    dft['hedge_cumulative'] = [0] + dft.iloc[1:].hedge.cumsum().values.tolist()\n",
    "\n",
    "    if use_fast:\n",
    "        dft['hedged_value'] = np.maximum(dft.current_hedge_strike.values,dft.close.values) - dft.hedge_cumulative.values\n",
    "        dft['prev_hedged_value'] = dft.hedged_value.shift(1)\n",
    "        dft['hedged_daily_return'] = dft.hedged_value/dft.prev_hedged_value-1\n",
    "        dft['prev_close'] = dft.close.shift(1)\n",
    "        dft['unhedged_return']  = dft.close/dft.prev_close-1\n",
    "    else:\n",
    "        dft['hedged_value'] = dft.apply(lambda r:max(r.current_hedge_strike,r.close) - r.hedge_cumulative,axis=1)\n",
    "        dft['prev_hedged_value'] = dft.hedged_value.shift(1)\n",
    "        dft['hedged_daily_return'] = dft.apply(lambda r:r.hedged_value/r.prev_hedged_value-1,axis=1)\n",
    "        dft['prev_close'] = dft.close.shift(1)\n",
    "        dft['unhedged_return']  = dft.apply(lambda r:r.close/r.prev_close-1,axis=1) \n",
    "    \n",
    "    \n",
    "    # Return dft\n",
    "    return dft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 03: Define method that calculates \"comparative\" returns.\n",
    "1. Return of unhedged portofolio\n",
    "2. Return of hedged portfolio\n",
    "3. Return of a partially invested portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparative_returns(dft,years_to_hedge,rebal_target,rebal_adjust,pom=.14):\n",
    "    ret = {}\n",
    "    \n",
    "    # Get the begin and end values of dft.close, using the lowest and highest dates\n",
    "    row_min = dft[dft.settle_dt == dft.settle_dt.min()].iloc[0]\n",
    "    row_max = dft[dft.settle_dt == dft.settle_dt.max()].iloc[0]\n",
    "    years_of_position = (row_max.settle_dt - row_min.settle_dt).days/365\n",
    "    beg_value = row_min.close\n",
    "    curr_value  = row_max.close\n",
    "    \n",
    "    # Caculate various returns\n",
    "    #   return not hedged\n",
    "    curr_return  = (curr_value/beg_value)**(1/years_of_position) - 1\n",
    "    #   return as of the date of the highest high\n",
    "    highest_high_value = dft[dft.high==dft.high.max()].iloc[0].close\n",
    "    highest_return_no_hedge = (highest_high_value/beg_value)**(1/years_of_position) - 1\n",
    "\n",
    "    #   current return if you hedged\n",
    "    hedge_cost = dft[dft.time_to_hedge].hedge.sum()\n",
    "    hedged_value = max(row_max.current_hedge_strike,curr_value) - hedge_cost\n",
    "    hedged_return = (hedged_value/beg_value)**(1/years_of_position) - 1\n",
    "\n",
    "    # Calculate the return from a portfolio that is rebalanced when the portfolio's\n",
    "    #     percentage of stock reaches some threshold.\n",
    "    \n",
    "    # Get the initial shares of stock and cash\n",
    "    shares = rebal_target / dft.close[0]\n",
    "    cash = 1 - rebal_target\n",
    "    # Set up arrays to accumlate daily changes\n",
    "    cash_per_day = []\n",
    "    stock_per_day = []\n",
    "    port_per_day = []\n",
    "    prices = dft.close.values\n",
    "    dates = dft.settle_date.values\n",
    "    cash_rates = dft.rate.values / 365\n",
    "    rebal_dates = []\n",
    "    rebal_sales = []\n",
    "    stock_percs = []\n",
    "\n",
    "    # Main loop to determine portfolio values over time, and to determine when to rebalance\n",
    "    for i in range(1,len(dft)):\n",
    "        # Calculate current stock dollars\n",
    "        stock_dollars = shares * prices[i]\n",
    "        # have your cash earn interest each day\n",
    "        cash_rate = cash_rates[i]\n",
    "        cash = cash * (1+cash_rate)\n",
    "        # determine portfolio value \n",
    "        port = stock_dollars + cash\n",
    "        # determine pre-rebalance stock percent\n",
    "        stock_perc = stock_dollars/port\n",
    "        stock_percs.append(stock_perc)\n",
    "        # determine if you should rebalance\n",
    "        if stock_perc >= rebal_adjust:\n",
    "            # do upside re-balance\n",
    "            dollars_to_sell = stock_dollars - rebal_target*port\n",
    "            new_stock_dollars = stock_dollars - dollars_to_sell\n",
    "            new_cash = cash + dollars_to_sell\n",
    "            new_port = new_stock_dollars + new_cash\n",
    "            shares = new_stock_dollars/prices[i]\n",
    "            cash = new_cash\n",
    "            stock_dollars = new_stock_dollars\n",
    "            rebal_dates.append(dates[i])\n",
    "            rebal_sales.append(dollars_to_sell)\n",
    "        elif stock_perc <= (rebal_target - (rebal_adjust-rebal_target)):\n",
    "            # do downside re-balance\n",
    "            dollars_to_buy = rebal_target*port - stock_dollars\n",
    "            new_stock_dollars = stock_dollars + dollars_to_buy\n",
    "            new_cash = cash - dollars_to_buy\n",
    "            new_port = new_stock_dollars + new_cash\n",
    "            shares = new_stock_dollars/prices[i]\n",
    "            cash = new_cash\n",
    "            stock_dollars = new_stock_dollars\n",
    "            rebal_dates.append(dates[i])\n",
    "            rebal_sales.append(-dollars_to_buy)\n",
    "            \n",
    "        cash_per_day.append(cash)\n",
    "        stock_per_day.append(stock_dollars)\n",
    "        port_per_day.append(cash+stock_dollars)    \n",
    "    \n",
    "    df_daily_values = pd.DataFrame({\n",
    "        'cash_per_day':cash_per_day,\n",
    "        'stock_per_day':stock_per_day,\n",
    "        'port_per_day':port_per_day,\n",
    "        'close':prices[1:],\n",
    "        'date':dates[1:],\n",
    "        'cash_rate':cash_rates[1:],\n",
    "        'stock_perc':stock_percs\n",
    "    })\n",
    "    df_rebalance_info = pd.DataFrame({\n",
    "        'rebal_date':rebal_dates,\n",
    "        'rebal_sale':rebal_sales,\n",
    "    })\n",
    "    # get total years and calculate annualized portfolio performance\n",
    "    total_days = (dft.settle_dt.values[-1] - dft.settle_dt.values[0]).astype('timedelta64[D]')// np.timedelta64(1, 'D')\n",
    "    total_years = total_days / 365\n",
    "    end_port_value = port_per_day[-1]\n",
    "    beg_port_value = port_per_day[0]\n",
    "    annualized_port_yield = round((end_port_value/beg_port_value)**(1/total_years) - 1,3)\n",
    "    return_types = [\n",
    "        'total years',\n",
    "        'annualized current return',\n",
    "        f'annualized highest return',\n",
    "        f'annualized current hedged return {round(pom*100,1)}%',\n",
    "        f'rebalanced ({int(rebal_target*100)}%,{int(rebal_adjust*100)}%) portfolio end value']\n",
    "    df_values = pd.DataFrame({\n",
    "        'return_type':return_types,\n",
    "        'current_value':[total_years,curr_value,highest_high_value,hedged_value,end_port_value],\n",
    "        'return':[0,curr_return,highest_return_no_hedge,hedged_return,annualized_port_yield]})\n",
    "    return df_values,df_daily_values,df_rebalance_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 04: Create methods to convert input strings of:\n",
    "1. beg_date in format yyyy-mm-dd (e.g. 1990-01-02 for Jan 2nd, 1990)\n",
    "2. beg_date in format yyyy-mm-dd (e.g. 1990-01-02 for Jan 2nd, 1990)\n",
    "3. put percent out of the money as decimal (e.g .14 for 14% out of the money)\n",
    "\n",
    "#### into DataFrames and Graph Figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_all_scenarios(beg_year,end_year,low_pom,high_pom,rebal_target,rebal_adjust):\n",
    "    # determine yyyymmdd_end\n",
    "    dt_now = datetime.datetime.now()\n",
    "    yyyymmdd_end = end_year*100*100 + 1231\n",
    "    yyyymmdd_now = dt_to_yyyymmdd(dt_now)\n",
    "    yyyymmdd_end = min(yyyymmdd_end,yyyymmdd_now)\n",
    "    # create array of beg_years to loop on\n",
    "    beg_years = np.arange(beg_year,end_year,1)\n",
    "\n",
    "    #   loop on increasing beg_year, but holding end_year constant\n",
    "    dft_dict = {}\n",
    "    data_inputs = DataInputs()\n",
    "    year_begs = []\n",
    "    poms = []\n",
    "    no_hedge_currents = []\n",
    "    no_hedge_highests = []\n",
    "    with_hedge_currents = []\n",
    "    rebalanced_currents = []\n",
    "    for y in tqdm_notebook(beg_years):\n",
    "        yyyymmdd_beg = int(y)*100*100 + 101 \n",
    "        #    loop on pom\n",
    "        for pom in [round(x,2) for x in np.arange(low_pom,high_pom+.01,.02)]:\n",
    "            _,df_values,_,_ =_get_df_values(\n",
    "                yyyymmdd_beg,yyyymmdd_end,pom,rebal_target,rebal_adjust,\n",
    "                data_inputs=data_inputs)\n",
    "            year_begs.append(y)\n",
    "            poms.append(pom)\n",
    "            no_hedge_currents.append(df_values.iloc[1]['return'])\n",
    "            no_hedge_highests.append(df_values.iloc[2]['return'])\n",
    "            with_hedge_currents.append(df_values.iloc[3]['return'])\n",
    "            rebalanced_currents.append(df_values.iloc[4]['return'])\n",
    "    return pd.DataFrame(\n",
    "        {'year_beg':year_begs,'pom':poms,'no_hedge_current':no_hedge_currents,\n",
    "         'no_hedge_highest':no_hedge_highests,'with_hedge_current':with_hedge_currents,\n",
    "         'rebalanced_current':rebalanced_currents})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 05: Create scenarios for 3d display of returns vs year, percent out of money (pom), and rebalance percentages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_df_values_from_input_data(input_data):\n",
    "    bd = input_data[0]\n",
    "    ed = input_data[1]\n",
    "    perc_otm_string = input_data[2]\n",
    "    rebal_target_string = input_data[3]\n",
    "    rebal_adjust_string = input_data[4]\n",
    "    yyyymmdd_beg = int(bd[0:4])*100*100 + int(bd[5:7])*100 + int(bd[8:10])\n",
    "    yyyymmdd_end = int(ed[0:4])*100*100 + int(ed[5:7])*100 + int(ed[8:10])\n",
    "    new_pom = float(perc_otm_string)\n",
    "    new_rebal_target = float(rebal_target_string)\n",
    "    new_rebal_adjust = float(rebal_adjust_string)\n",
    "    return _get_df_values(yyyymmdd_beg,yyyymmdd_end,new_pom,new_rebal_target,new_rebal_adjust)\n",
    "\n",
    "def _get_df_values(yyyymmdd_beg,yyyymmdd_end,pom,rebal_target,rebal_adjust,\n",
    "                   years_to_hedge=1,data_inputs=None):\n",
    "    # validate values\n",
    "    new_pom = pom\n",
    "    new_rebal_target = rebal_target\n",
    "    new_rebal_adjust = rebal_adjust\n",
    "    dft_new = create_dft(new_pom,years_to_hedge,\n",
    "                       yyyymmdd_beg=yyyymmdd_beg,yyyymmdd_end=yyyymmdd_end,\n",
    "                        data_inputs=data_inputs)\n",
    "\n",
    "    df_values,df_daily_values,df_rebalance_info = create_comparative_returns(\n",
    "        dft_new,years_to_hedge,new_rebal_target,new_rebal_adjust,pom=new_pom)\n",
    "    df_values.current_value = df_values.current_value.round(3) \n",
    "    df_values['return'] = df_values['return'].round(3) \n",
    "    return dft_new,df_values,df_daily_values,df_rebalance_info\n",
    "\n",
    "\n",
    "def _get_close_vs_hedge_stock_vs_cash_figure(input_data):\n",
    "    dft_new,df_values,df_daily_values,_ = _get_df_values_from_input_data(input_data)\n",
    "    df_daily_values['current_hedge_strike'] = dft_new.current_hedge_strike\n",
    "    names = ['stock_perc','port_per_day','close','current_hedge_strike']\n",
    "    x_columns = ['date' for _ in range(len(names))]\n",
    "    yp_rows = [1,1,1,1]\n",
    "    yp_cols = [1,1,2,2]\n",
    "    yp_secondary = [False,True,False,False]\n",
    "    yp_yaxis_titles = ['Stock Percent','Portolio Value','S&P Price / Hedge Strike','S&P Price / Hedge Strike']\n",
    "    df_yp = pd.DataFrame({'name':names,'x_column':x_columns,\n",
    "                      'row':yp_rows,'col':yp_cols,'is_secondary':yp_secondary,\n",
    "                     'yaxis_title':yp_yaxis_titles})\n",
    "    sp_titles = ['Stock Perc vs Portfolio Value','S&P Price vs Hedge Strike']\n",
    "    fig =  dashapp.plotly_subplots(df_daily_values,df_yp,title=\"Portfolio Analysis\",\n",
    "                      num_ticks_to_display=10,subplot_titles=sp_titles) \n",
    "    fig = go.Figure(fig)\n",
    "    fig.update_layout(\n",
    "        legend=dict(x=-0.1, y=1.4),\n",
    "        modebar={'orientation': 'v','bgcolor':'grey'}\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "def _get_scenarios_data_old(input_data):\n",
    "    beg_year = int(str(input_data[0]))\n",
    "    end_year = int(str(input_data[1]))\n",
    "    beg_pom = float(str(input_data[2]))\n",
    "    end_pom = float(str(input_data[3]))  \n",
    "    all3_query = f\"(year>={beg_year}) and (year<={end_year}) and (pom>={beg_pom}) and (pom<={end_pom})\"\n",
    "    dft_dict = build_scenarios(beg_year,end_year,beg_pom,end_pom,.6,.7)\n",
    "    df_all3,df_all = build_3d_display_df(dft_dict)\n",
    "    df_all3_scenarios = df_all3.query(all3_query)\n",
    "    return [{'df_all3':df_all3_scenarios.to_dict('rows'),'df_all':df_all.to_dict('rows')}]\n",
    "\n",
    "def _get_scenarios_data(input_data):\n",
    "    global df_every_scenario\n",
    "    beg_year = int(str(input_data[0]))\n",
    "    end_year = int(str(input_data[1]))\n",
    "    beg_pom = float(str(input_data[2]))\n",
    "    end_pom = float(str(input_data[3]))  \n",
    "#     dft_dict = build_scenarios(beg_year,end_year,beg_pom,end_pom,.6,.7)\n",
    "#     df_all3,df_all = build_3d_display_df(dft_dict)\n",
    "    \n",
    "    yb = df_every_scenario.year_beg>=beg_year\n",
    "    ye = df_every_scenario.year_end==end_year\n",
    "    bp = df_every_scenario.pom>=beg_pom\n",
    "    ep = df_every_scenario.pom<=end_pom\n",
    "    df_all = df_every_scenario[yb & ye & bp & ep]\n",
    "    cols = ['year_beg','pom','no_hedge_current','no_hedge_highest','with_hedge_current','rebalanced_current']\n",
    "    df_all = df_all[cols]\n",
    "    df_all = df_all.rename(columns={'year_beg':'year'})\n",
    "\n",
    "    df_all2 = df_all[['year','pom','no_hedge_current']].copy()\n",
    "    df_all2 = df_all2.rename(columns={'no_hedge_current':'ret'})\n",
    "    df_all2['ret_type'] = 'no_hedge_current'\n",
    "    df_all2.index = list(range(len(df_all2)))\n",
    "    for c in ['no_hedge_highest','with_hedge_current','rebalanced_current']:\n",
    "        df_temp = df_all[['year','pom',c]].copy()\n",
    "        df_temp.index=list(range(len(df_temp)))\n",
    "        df_temp = df_temp.rename(columns={c:'ret'})\n",
    "        df_temp['ret_type'] = c\n",
    "        df_all2 = df_all2.append(df_temp,ignore_index=True)\n",
    "        df_all2.index = list(range(len(df_all2)))\n",
    "    df_all2.ret_type.unique()\n",
    "    df_all3 = df_all2.query(\"ret_type in ['with_hedge_current','rebalanced_current']\")\n",
    "    return [{'df_all3':df_all3.to_dict('rows'),'df_all':df_all.to_dict('rows')}]\n",
    "    \n",
    "\n",
    "def _get_scenarios_figure_from_data(input_data):\n",
    "    df_all3_scenarios = pd.DataFrame(input_data[0]['df_all3'])\n",
    "    fig = px.scatter_3d(df_all3_scenarios, x='pom', y='year', z='ret',color='ret_type')\n",
    "    fig.update_layout(\n",
    "        legend=dict(x=-0.1, y=1.2),\n",
    "        modebar={'orientation': 'v','bgcolor':'grey'}\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def make_page_title(title_text,div_id=None,html_container=None,parent_class=None,\n",
    "                   panel_background_color='#CAE2EB'):\n",
    "    par_class = parent_class\n",
    "    if par_class is None:\n",
    "        par_class = dashapp.pnnm\n",
    "    htmc = html_container\n",
    "    if htmc is None:\n",
    "        htmc = html.H2\n",
    "        \n",
    "    title_parts = title_text.split('\\n')\n",
    "    \n",
    "\n",
    "    title_list = [htmc(tp,className=dashapp.pnncnm) for tp in title_parts]\n",
    "    r = dashapp.multi_row_panel(title_list,\n",
    "                 parent_class=par_class,\n",
    "                 div_id=div_id,\n",
    "                 panel_background_color=panel_background_color) \n",
    "    return r   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 06: Define rows of the displayed single page web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_put_perc_otm=.14\n",
    "# init_low_pom = .10\n",
    "# init_high_pom = .18\n",
    "# init_rebal_target = .6\n",
    "# init_rebal_adjust = .7\n",
    "# init_years_to_hedge=1\n",
    "# init_beg_year = 1990\n",
    "# init_beg_yyyymmdd = init_beg_year*100*100 + 701\n",
    "# init_end_yyyymmdd = 203001010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_db():\n",
    "    df_every_scenario = None\n",
    "    for y in tqdm_notebook(range(2000,2021,1)):\n",
    "        df_1 = build_all_scenarios(1990,y,.1,.18,.6,.7)\n",
    "        df_1['year_end'] = y\n",
    "        if df_every_scenario is None:\n",
    "            df_every_scenario = df_1.copy()\n",
    "        else:\n",
    "            df_every_scenario = df_every_scenario.append(df_1,ignore_index=True)\n",
    "        df_every_scenario.index = list(range(len(df_every_scenario)))    \n",
    "    update_redis_df('df_every_scenario',df_every_scenario)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bperlman1/Virtualenvs3/dashrisk5/lib/python3.6/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning:\n",
      "\n",
      "This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c516febc4b4448384c9c860b79213d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bperlman1/Virtualenvs3/dashrisk5/lib/python3.6/site-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning:\n",
      "\n",
      "This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8028a5e02e48a6b0482f30442f6bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 17:15:02,464 - numexpr.utils - INFO - NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d30345b4fae4e99afe65952f9264e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfa617c66b54668a8f22e148b57bfe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40265ac349b4e639542abeb57fb3077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b39efaadc0475092394409fa74dddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558d7d1c6018403fb8f0261d4d53a408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0d0c24f21745c3bc17b8e0e767a30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfea489753164de2879ce15aef79cc38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7247703c0ab431b957f3999fd73672f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3377de47a7473a87257e143f86bdce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff37e1174fc4c9199ae1534a8e135cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05ec3d34a0547499342089db85b6cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58194806a444b3ea8f46d743558a135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7925a8a5dab40c9a91a9ef65deaa923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8881b05d23b41c894c1afc152c5cadb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b5f585dfd74e9f8d1bb5c4ffea4782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db87a4d60ef49878b4afdeb98eb784d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0f926973f24baf86ca78b261587f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c739c82f0c4918a0794bb2875d4a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9613ee1927d42a1b0a24c794169c0ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692aa90bbf5d435aa56ec99cbf7ff22b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 17:18:23,140 - root - INFO - scheduling update for hour 8\n",
      "2020-07-09 17:18:23,223 - root - INFO - Sleeping at time 2020-07-09 17:18:23.222979-04:00 for 14.693611 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3aee1afc2cbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mupdate_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mschedule_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mupdate_db\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-e4a05d9b0e3c>\u001b[0m in \u001b[0;36mschedule_updates\u001b[0;34m(hour, update_callback)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"scheduling update for hour {hour}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule_it\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScheduleNext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hour'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhour\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0msch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"updating history\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mupdate_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/billybyte/pyliverisk/barchartacs/barchartacs/schedule_it.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sleeping at time %s for %f hours\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msecs_to_wait\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3600.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecs_to_wait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Waking at time: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    update_db()\n",
    "    schedule_updates(8,update_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script redis_create_dps_all_scenarios.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
